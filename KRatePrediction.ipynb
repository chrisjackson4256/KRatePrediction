{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting MLB Strikeout Rates from Velocity and Movement\n",
    "\n",
    "Using data from 2012-2016, we first determine a classification system for different pitches using a clustering algorithm.  Motivation for this work was provided by http://www.sloansportsconference.com/wp-content/uploads/2019/02/Predicting-Major-League-Baseball-Strikeout-Rates-Update.pdf.\n",
    "\n",
    "These features are then used to construct a model to predict strikeout rates using several regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybaseball import statcast, pitching_stats, pitching_stats_range\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data\n",
    "\n",
    "The raw data is scraped from statcast and/or pitch fx using the pybaseball module.  We remove \"short relievers\" by keeping only pitchers that have thrown at least 1000 pitches in a season AND that average 10 batters faced per appearance.\n",
    "\n",
    "The data columns used from the pitcher data are:\n",
    "\n",
    "- game_pk: the unique game ID\n",
    "- inning: inning of the pitch\n",
    "- game_year: the year of the data\n",
    "- player_name: the pitcher's name (this is used to join to a separate data pull that is required to extract strikeouts per 9 innings)\n",
    "- batter: used to keep track of batters faced\n",
    "- release_speed: speed of the ball at time of release (feature used for pitch categorization in the clustering algorithm)\n",
    "- pfx_x, pfx_z: movement in the horizontal and vertical directions (features used for pitch categorization in the clustering algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_batters_faced(df, pitcher_id):\n",
    "    \n",
    "    # subset the given pitcher's games\n",
    "    temp_df = df[df['pitcher']==pitcher_id]\n",
    "    \n",
    "    # count number of batters faced in each game\n",
    "    temp_df = temp_df.drop_duplicates(subset=['game_pk', 'inning', 'batter'])\n",
    "    total_batters_faced = len(temp_df)\n",
    "\n",
    "    # count the number of appearances\n",
    "    number_of_games = len(temp_df['game_pk'].unique())\n",
    "    \n",
    "    # return the average number of batters faced per game\n",
    "    return round(total_batters_faced / number_of_games, 1)\n",
    "\n",
    "\n",
    "def get_speed_location_data(start, end):\n",
    "\n",
    "    # get the raw pitch data from statcast\n",
    "    pitch_data = statcast(start_dt=start, end_dt=end)\n",
    "    \n",
    "    # make sure index columns are int\n",
    "    pitch_data['game_pk'] = pitch_data['game_pk'].astype(int)\n",
    "    pitch_data['inning'] = pitch_data['inning'].astype(int)\n",
    "    pitch_data['game_year'] = pitch_data['game_year'].astype(int)\n",
    "    pitch_data['pitcher'] = pitch_data['pitcher'].astype(int)\n",
    "    pitch_data['batter'] = pitch_data['batter'].astype(int)\n",
    "    \n",
    "    # get the data for K rate and to compute the pitcher's strike percentage\n",
    "    strike_data = pitching_stats(start[:4])\n",
    "    strike_data = strike_data[['Season', 'Name', 'K/9', 'Pitches', 'Strikes']]\n",
    "    strike_data.columns = ['game_year', 'player_name', 'K/9', 'Pitches', 'Strikes']\n",
    "    strike_data['strike_pct'] = strike_data['Strikes'] / strike_data['Pitches']\n",
    "    strike_data.drop(['Pitches', 'Strikes'], axis=1, inplace=True)\n",
    "    strike_data['game_year'] = strike_data['game_year'].astype(int)\n",
    "    \n",
    "    # merge the two dataframes together\n",
    "    pitch_data = pd.merge(pitch_data, strike_data, how='inner', on=['game_year', 'player_name'])\n",
    "        \n",
    "    # select the columns that we need\n",
    "    cols_to_keep = ['game_pk', 'inning', 'game_year', 'player_name', 'pitcher', 'batter', 'release_speed', 'pfx_x', 'pfx_z', 'strike_pct', 'K/9']\n",
    "    pitch_data = pitch_data[cols_to_keep]\n",
    "    \n",
    "    # drop any rows that have no game_pk\n",
    "    pitch_data = pitch_data[~pd.isnull(pitch_data['game_pk'])]\n",
    "    \n",
    "    # make an index for observations \n",
    "    pitch_data['obs_index'] = pitch_data['game_year'].astype(str) + \"_\" + pitch_data['pitcher'].astype(str)\n",
    "    \n",
    "    # get a count of pitchers and number of pitches they threw\n",
    "    pitcher_count = dict(Counter(pitch_data['pitcher']))\n",
    "\n",
    "    # list of pitchers with at least 1000 pitches thrown\n",
    "    pitchers_w_1000pitches = [k for k, v in pitcher_count.items() if v >= 1000]\n",
    "    \n",
    "    # subset the dataframe to those pitchers with at least 1000 pitches thrown\n",
    "    pitch_data = pitch_data[pitch_data['pitcher'].isin(pitchers_w_1000pitches)]\n",
    "    \n",
    "    # list of pitchers with at least 1000 pitches thrown AND average number of batters faced per outing greater than 10\n",
    "    pitchers_no_short = [x for x in pitchers_w_1000pitches if avg_batters_faced(pitch_data, x) >= 10.0]\n",
    "\n",
    "    # subset the dataframe to those pitchers with at least 1000 pitches thrown\n",
    "    pitch_data = pitch_data[pitch_data['pitcher'].isin(pitchers_no_short)]\n",
    "        \n",
    "    # keep only columns we need\n",
    "    pitch_data = pitch_data[['obs_index', 'pitcher', 'player_name', 'release_speed', 'pfx_x', 'pfx_z', 'strike_pct', 'K/9']]\n",
    "        \n",
    "    return pitch_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the data using pybaseball\n",
    "\n",
    "Fill in the start and end dates of the season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2012-03-28 to 2012-04-02\n",
      "Completed sub-query from 2012-04-03 to 2012-04-08\n",
      "Completed sub-query from 2012-04-09 to 2012-04-14\n",
      "Completed sub-query from 2012-04-15 to 2012-04-20\n",
      "Completed sub-query from 2012-04-21 to 2012-04-26\n",
      "Completed sub-query from 2012-04-27 to 2012-05-02\n",
      "Completed sub-query from 2012-05-03 to 2012-05-08\n",
      "Completed sub-query from 2012-05-09 to 2012-05-14\n",
      "Completed sub-query from 2012-05-15 to 2012-05-20\n",
      "Completed sub-query from 2012-05-21 to 2012-05-26\n",
      "Completed sub-query from 2012-05-27 to 2012-06-01\n",
      "Completed sub-query from 2012-06-02 to 2012-06-07\n",
      "Completed sub-query from 2012-06-08 to 2012-06-13\n",
      "Completed sub-query from 2012-06-14 to 2012-06-19\n",
      "Completed sub-query from 2012-06-20 to 2012-06-25\n",
      "Completed sub-query from 2012-06-26 to 2012-07-01\n",
      "Completed sub-query from 2012-07-02 to 2012-07-07\n",
      "Completed sub-query from 2012-07-08 to 2012-07-13\n",
      "Completed sub-query from 2012-07-14 to 2012-07-19\n",
      "Completed sub-query from 2012-07-20 to 2012-07-25\n",
      "Completed sub-query from 2012-07-26 to 2012-07-31\n",
      "Completed sub-query from 2012-08-01 to 2012-08-06\n",
      "Completed sub-query from 2012-08-07 to 2012-08-12\n",
      "Completed sub-query from 2012-08-13 to 2012-08-18\n",
      "Completed sub-query from 2012-08-19 to 2012-08-24\n",
      "Completed sub-query from 2012-08-25 to 2012-08-30\n",
      "Completed sub-query from 2012-08-31 to 2012-09-05\n",
      "Completed sub-query from 2012-09-06 to 2012-09-11\n",
      "Completed sub-query from 2012-09-12 to 2012-09-17\n",
      "Completed sub-query from 2012-09-18 to 2012-09-23\n",
      "Completed sub-query from 2012-09-24 to 2012-09-29\n",
      "Completed sub-query from 2012-09-30 to 2012-10-03\n",
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2013-03-31 to 2013-04-05\n",
      "Completed sub-query from 2013-04-06 to 2013-04-11\n",
      "Completed sub-query from 2013-04-12 to 2013-04-17\n",
      "Completed sub-query from 2013-04-18 to 2013-04-23\n",
      "Completed sub-query from 2013-04-24 to 2013-04-29\n",
      "Completed sub-query from 2013-04-30 to 2013-05-05\n",
      "Completed sub-query from 2013-05-06 to 2013-05-11\n",
      "Completed sub-query from 2013-05-12 to 2013-05-17\n",
      "Completed sub-query from 2013-05-18 to 2013-05-23\n",
      "Completed sub-query from 2013-05-24 to 2013-05-29\n",
      "Completed sub-query from 2013-05-30 to 2013-06-04\n",
      "Completed sub-query from 2013-06-05 to 2013-06-10\n",
      "Completed sub-query from 2013-06-11 to 2013-06-16\n",
      "Completed sub-query from 2013-06-17 to 2013-06-22\n",
      "Completed sub-query from 2013-06-23 to 2013-06-28\n",
      "Completed sub-query from 2013-06-29 to 2013-07-04\n",
      "Completed sub-query from 2013-07-05 to 2013-07-10\n",
      "Completed sub-query from 2013-07-11 to 2013-07-16\n",
      "Completed sub-query from 2013-07-17 to 2013-07-22\n",
      "Completed sub-query from 2013-07-23 to 2013-07-28\n",
      "Completed sub-query from 2013-07-29 to 2013-08-03\n",
      "Completed sub-query from 2013-08-04 to 2013-08-09\n",
      "Completed sub-query from 2013-08-10 to 2013-08-15\n",
      "Completed sub-query from 2013-08-16 to 2013-08-21\n",
      "Completed sub-query from 2013-08-22 to 2013-08-27\n",
      "Completed sub-query from 2013-08-28 to 2013-09-02\n",
      "Completed sub-query from 2013-09-03 to 2013-09-08\n",
      "Completed sub-query from 2013-09-09 to 2013-09-14\n",
      "Completed sub-query from 2013-09-15 to 2013-09-20\n",
      "Completed sub-query from 2013-09-21 to 2013-09-26\n",
      "Completed sub-query from 2013-09-27 to 2013-09-30\n",
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2014-03-22 to 2014-03-27\n",
      "Completed sub-query from 2014-03-28 to 2014-04-02\n",
      "Completed sub-query from 2014-04-03 to 2014-04-08\n",
      "Completed sub-query from 2014-04-09 to 2014-04-14\n",
      "Completed sub-query from 2014-04-15 to 2014-04-20\n",
      "Completed sub-query from 2014-04-21 to 2014-04-26\n",
      "Completed sub-query from 2014-04-27 to 2014-05-02\n",
      "Completed sub-query from 2014-05-03 to 2014-05-08\n",
      "Completed sub-query from 2014-05-09 to 2014-05-14\n",
      "Completed sub-query from 2014-05-15 to 2014-05-20\n",
      "Completed sub-query from 2014-05-21 to 2014-05-26\n",
      "Completed sub-query from 2014-05-27 to 2014-06-01\n",
      "Completed sub-query from 2014-06-02 to 2014-06-07\n",
      "Completed sub-query from 2014-06-08 to 2014-06-13\n",
      "Completed sub-query from 2014-06-14 to 2014-06-19\n",
      "Completed sub-query from 2014-06-20 to 2014-06-25\n",
      "Completed sub-query from 2014-06-26 to 2014-07-01\n",
      "Completed sub-query from 2014-07-02 to 2014-07-07\n",
      "Completed sub-query from 2014-07-08 to 2014-07-13\n",
      "Completed sub-query from 2014-07-14 to 2014-07-19\n",
      "Completed sub-query from 2014-07-20 to 2014-07-25\n",
      "Completed sub-query from 2014-07-26 to 2014-07-31\n",
      "Completed sub-query from 2014-08-01 to 2014-08-06\n",
      "Completed sub-query from 2014-08-07 to 2014-08-12\n",
      "Completed sub-query from 2014-08-13 to 2014-08-18\n",
      "Completed sub-query from 2014-08-19 to 2014-08-24\n",
      "Completed sub-query from 2014-08-25 to 2014-08-30\n",
      "Completed sub-query from 2014-08-31 to 2014-09-05\n",
      "Completed sub-query from 2014-09-06 to 2014-09-11\n",
      "Completed sub-query from 2014-09-12 to 2014-09-17\n",
      "Completed sub-query from 2014-09-18 to 2014-09-23\n",
      "Completed sub-query from 2014-09-24 to 2014-09-28\n",
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2015-04-05 to 2015-04-10\n",
      "Completed sub-query from 2015-04-11 to 2015-04-16\n",
      "Completed sub-query from 2015-04-17 to 2015-04-22\n",
      "Completed sub-query from 2015-04-23 to 2015-04-28\n",
      "Completed sub-query from 2015-04-29 to 2015-05-04\n",
      "Completed sub-query from 2015-05-05 to 2015-05-10\n",
      "Completed sub-query from 2015-05-11 to 2015-05-16\n",
      "Completed sub-query from 2015-05-17 to 2015-05-22\n",
      "Completed sub-query from 2015-05-23 to 2015-05-28\n",
      "Completed sub-query from 2015-05-29 to 2015-06-03\n",
      "Completed sub-query from 2015-06-04 to 2015-06-09\n",
      "Completed sub-query from 2015-06-10 to 2015-06-15\n",
      "Completed sub-query from 2015-06-16 to 2015-06-21\n",
      "Completed sub-query from 2015-06-22 to 2015-06-27\n",
      "Completed sub-query from 2015-06-28 to 2015-07-03\n",
      "Completed sub-query from 2015-07-04 to 2015-07-09\n",
      "Completed sub-query from 2015-07-10 to 2015-07-15\n",
      "Completed sub-query from 2015-07-16 to 2015-07-21\n",
      "Completed sub-query from 2015-07-22 to 2015-07-27\n",
      "Completed sub-query from 2015-07-28 to 2015-08-02\n",
      "Completed sub-query from 2015-08-03 to 2015-08-08\n",
      "Completed sub-query from 2015-08-09 to 2015-08-14\n",
      "Completed sub-query from 2015-08-15 to 2015-08-20\n",
      "Completed sub-query from 2015-08-21 to 2015-08-26\n",
      "Completed sub-query from 2015-08-27 to 2015-09-01\n",
      "Completed sub-query from 2015-09-02 to 2015-09-07\n",
      "Completed sub-query from 2015-09-08 to 2015-09-13\n",
      "Completed sub-query from 2015-09-14 to 2015-09-19\n",
      "Completed sub-query from 2015-09-20 to 2015-09-25\n",
      "Completed sub-query from 2015-09-26 to 2015-10-01\n",
      "Completed sub-query from 2015-10-02 to 2015-10-04\n",
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2016-04-03 to 2016-04-08\n",
      "Completed sub-query from 2016-04-09 to 2016-04-14\n",
      "Completed sub-query from 2016-04-15 to 2016-04-20\n",
      "Completed sub-query from 2016-04-21 to 2016-04-26\n",
      "Completed sub-query from 2016-04-27 to 2016-05-02\n",
      "Completed sub-query from 2016-05-03 to 2016-05-08\n",
      "Completed sub-query from 2016-05-09 to 2016-05-14\n",
      "Completed sub-query from 2016-05-15 to 2016-05-20\n",
      "Completed sub-query from 2016-05-21 to 2016-05-26\n",
      "Completed sub-query from 2016-05-27 to 2016-06-01\n",
      "Completed sub-query from 2016-06-02 to 2016-06-07\n",
      "Completed sub-query from 2016-06-08 to 2016-06-13\n",
      "Completed sub-query from 2016-06-14 to 2016-06-19\n",
      "Completed sub-query from 2016-06-20 to 2016-06-25\n",
      "Completed sub-query from 2016-06-26 to 2016-07-01\n",
      "Completed sub-query from 2016-07-02 to 2016-07-07\n",
      "Completed sub-query from 2016-07-08 to 2016-07-13\n",
      "Completed sub-query from 2016-07-14 to 2016-07-19\n",
      "Completed sub-query from 2016-07-20 to 2016-07-25\n",
      "Completed sub-query from 2016-07-26 to 2016-07-31\n",
      "Completed sub-query from 2016-08-01 to 2016-08-06\n",
      "Completed sub-query from 2016-08-07 to 2016-08-12\n",
      "Completed sub-query from 2016-08-13 to 2016-08-18\n",
      "Completed sub-query from 2016-08-19 to 2016-08-24\n",
      "Completed sub-query from 2016-08-25 to 2016-08-30\n",
      "Completed sub-query from 2016-08-31 to 2016-09-05\n",
      "Completed sub-query from 2016-09-06 to 2016-09-11\n",
      "Completed sub-query from 2016-09-12 to 2016-09-17\n",
      "Completed sub-query from 2016-09-18 to 2016-09-23\n",
      "Completed sub-query from 2016-09-24 to 2016-09-29\n",
      "Completed sub-query from 2016-09-30 to 2016-10-02\n",
      "Shape of training data: (2108087, 8)\n",
      "Number of unique pitchers in training data: 355\n",
      "Number of unique observations in training data: 884\n"
     ]
    }
   ],
   "source": [
    "train_data_dates = [('2012-03-28', '2012-10-03'),\n",
    "                    ('2013-03-31', '2013-09-30'),\n",
    "                    ('2014-03-22', '2014-09-28'),\n",
    "                    ('2015-04-05', '2015-10-04'),\n",
    "                    ('2016-04-03', '2016-10-02')]\n",
    "\n",
    "train_data_list = []\n",
    "for dates in train_data_dates:\n",
    "    df = get_speed_location_data(start=dates[0], end=dates[1])\n",
    "    train_data_list.append(df)\n",
    "    \n",
    "train_data = pd.concat(train_data_list)\n",
    "print(f\"Shape of training data: {train_data.shape}\")\n",
    "print(f\"Number of unique pitchers in training data: {len(train_data['pitcher'].unique())}\")\n",
    "print(f\"Number of unique observations in training data: {len(train_data['obs_index'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n",
      "Completed sub-query from 2017-04-02 to 2017-04-07\n",
      "Completed sub-query from 2017-04-08 to 2017-04-13\n",
      "Completed sub-query from 2017-04-14 to 2017-04-19\n",
      "Completed sub-query from 2017-04-20 to 2017-04-25\n",
      "Completed sub-query from 2017-04-26 to 2017-05-01\n",
      "Completed sub-query from 2017-05-02 to 2017-05-07\n",
      "Completed sub-query from 2017-05-08 to 2017-05-13\n",
      "Completed sub-query from 2017-05-14 to 2017-05-19\n",
      "Completed sub-query from 2017-05-20 to 2017-05-25\n",
      "Completed sub-query from 2017-05-26 to 2017-05-31\n",
      "Completed sub-query from 2017-06-01 to 2017-06-06\n",
      "Completed sub-query from 2017-06-07 to 2017-06-12\n",
      "Completed sub-query from 2017-06-13 to 2017-06-18\n",
      "Completed sub-query from 2017-06-19 to 2017-06-24\n",
      "Completed sub-query from 2017-06-25 to 2017-06-30\n",
      "Completed sub-query from 2017-07-01 to 2017-07-06\n",
      "Completed sub-query from 2017-07-07 to 2017-07-12\n",
      "Completed sub-query from 2017-07-13 to 2017-07-18\n",
      "Completed sub-query from 2017-07-19 to 2017-07-24\n",
      "Completed sub-query from 2017-07-25 to 2017-07-30\n",
      "Completed sub-query from 2017-07-31 to 2017-08-05\n",
      "Completed sub-query from 2017-08-06 to 2017-08-11\n",
      "Completed sub-query from 2017-08-12 to 2017-08-17\n",
      "Completed sub-query from 2017-08-18 to 2017-08-23\n",
      "Completed sub-query from 2017-08-24 to 2017-08-29\n",
      "Completed sub-query from 2017-08-30 to 2017-09-04\n",
      "Completed sub-query from 2017-09-05 to 2017-09-10\n",
      "Completed sub-query from 2017-09-11 to 2017-09-16\n",
      "Completed sub-query from 2017-09-17 to 2017-09-22\n",
      "Completed sub-query from 2017-09-23 to 2017-09-28\n",
      "Completed sub-query from 2017-09-29 to 2017-10-01\n",
      "Shape of test data: (419462, 8)\n",
      "Number of unique pitchers in test data: 190\n",
      "Number of unique observations in test data: 190\n"
     ]
    }
   ],
   "source": [
    "test_data_dates = [('2017-04-02', '2017-10-01')]\n",
    "\n",
    "test_data_list = []\n",
    "for dates in test_data_dates:\n",
    "    df = get_speed_location_data(start=dates[0], end=dates[1])\n",
    "    test_data_list.append(df)\n",
    "    \n",
    "test_data = pd.concat(test_data_list)\n",
    "print(f\"Shape of test data: {test_data.shape}\")\n",
    "print(f\"Number of unique pitchers in test data: {len(test_data['pitcher'].unique())}\")\n",
    "print(f\"Number of unique observations in test data: {len(test_data['obs_index'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_index</th>\n",
       "      <th>pitcher</th>\n",
       "      <th>player_name</th>\n",
       "      <th>release_speed</th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>strike_pct</th>\n",
       "      <th>K/9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>2012_502706</td>\n",
       "      <td>502706</td>\n",
       "      <td>Derek Holland</td>\n",
       "      <td>82.7</td>\n",
       "      <td>0.067617</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>2012_502706</td>\n",
       "      <td>502706</td>\n",
       "      <td>Derek Holland</td>\n",
       "      <td>74.9</td>\n",
       "      <td>-0.580900</td>\n",
       "      <td>-0.348967</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>2012_502706</td>\n",
       "      <td>502706</td>\n",
       "      <td>Derek Holland</td>\n",
       "      <td>82.6</td>\n",
       "      <td>1.224092</td>\n",
       "      <td>1.223400</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>2012_502706</td>\n",
       "      <td>502706</td>\n",
       "      <td>Derek Holland</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1.392483</td>\n",
       "      <td>1.505767</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>2012_502706</td>\n",
       "      <td>502706</td>\n",
       "      <td>Derek Holland</td>\n",
       "      <td>80.8</td>\n",
       "      <td>1.141983</td>\n",
       "      <td>1.429800</td>\n",
       "      <td>0.638607</td>\n",
       "      <td>7.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        obs_index  pitcher    player_name  release_speed     pfx_x     pfx_z  \\\n",
       "6835  2012_502706   502706  Derek Holland           82.7  0.067617  0.019400   \n",
       "6836  2012_502706   502706  Derek Holland           74.9 -0.580900 -0.348967   \n",
       "6837  2012_502706   502706  Derek Holland           82.6  1.224092  1.223400   \n",
       "6838  2012_502706   502706  Derek Holland           94.0  1.392483  1.505767   \n",
       "6839  2012_502706   502706  Derek Holland           80.8  1.141983  1.429800   \n",
       "\n",
       "      strike_pct   K/9  \n",
       "6835    0.638607  7.44  \n",
       "6836    0.638607  7.44  \n",
       "6837    0.638607  7.44  \n",
       "6838    0.638607  7.44  \n",
       "6839    0.638607  7.44  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the pitch type cluster analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select the features that we use in the clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pitches in the clustering data: 2105256\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>release_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6835</th>\n",
       "      <td>0.067617</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>82.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6836</th>\n",
       "      <td>-0.580900</td>\n",
       "      <td>-0.348967</td>\n",
       "      <td>74.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>1.224092</td>\n",
       "      <td>1.223400</td>\n",
       "      <td>82.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>1.392483</td>\n",
       "      <td>1.505767</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>1.141983</td>\n",
       "      <td>1.429800</td>\n",
       "      <td>80.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pfx_x     pfx_z  release_speed\n",
       "6835  0.067617  0.019400           82.7\n",
       "6836 -0.580900 -0.348967           74.9\n",
       "6837  1.224092  1.223400           82.6\n",
       "6838  1.392483  1.505767           94.0\n",
       "6839  1.141983  1.429800           80.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_train_data = train_data[['pfx_x', 'pfx_z', 'release_speed']]\n",
    "cluster_train_data.dropna(inplace=True)\n",
    "\n",
    "print(f\"Number of pitches in the clustering data: {cluster_train_data.shape[0]}\\n\")\n",
    "cluster_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### standardize the data: scale the features to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pfx_x</th>\n",
       "      <th>pfx_z</th>\n",
       "      <th>release_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521931</td>\n",
       "      <td>0.444919</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.413785</td>\n",
       "      <td>0.399181</td>\n",
       "      <td>0.574534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714783</td>\n",
       "      <td>0.594412</td>\n",
       "      <td>0.694099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.742864</td>\n",
       "      <td>0.629471</td>\n",
       "      <td>0.871118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.701091</td>\n",
       "      <td>0.620039</td>\n",
       "      <td>0.666149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pfx_x     pfx_z  release_speed\n",
       "0  0.521931  0.444919       0.695652\n",
       "1  0.413785  0.399181       0.574534\n",
       "2  0.714783  0.594412       0.694099\n",
       "3  0.742864  0.629471       0.871118\n",
       "4  0.701091  0.620039       0.666149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfx_x_scaler = MinMaxScaler()\n",
    "\n",
    "pfx_x = cluster_train_data['pfx_x'].as_matrix().reshape(-1, 1)\n",
    "pfx_x_scaled = pd.DataFrame(pfx_x_scaler.fit_transform(pfx_x))\n",
    "\n",
    "pfx_z_scaler = MinMaxScaler()\n",
    "pfx_z = cluster_train_data['pfx_z'].as_matrix().reshape(-1, 1)\n",
    "pfx_z_scaled = pd.DataFrame(pfx_z_scaler.fit_transform(pfx_z))\n",
    "\n",
    "release_speed_scaler = MinMaxScaler()\n",
    "release_speed = cluster_train_data['release_speed'].as_matrix().reshape(-1, 1)\n",
    "release_speed_scaled = pd.DataFrame(release_speed_scaler.fit_transform(release_speed))\n",
    "\n",
    "cluster_train_data_scaled = pd.merge(pfx_x_scaled, pfx_z_scaled, left_index=True, right_index=True)\n",
    "cluster_train_data_scaled = pd.merge(cluster_train_data_scaled, release_speed_scaled, left_index=True, right_index=True)\n",
    "\n",
    "cluster_train_data_scaled.columns = ['pfx_x', 'pfx_z', 'release_speed']\n",
    "cluster_train_data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DBSCAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "db = DBSCAN(algorithm='ball_tree', n_jobs=-1).fit(cluster_train_data_scaled)\n",
    "labels = db.labels_\n",
    "k = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = list(labels).count(-1)\n",
    "\n",
    "print(f\"Optimal number of clusters: {k}\")\n",
    "print(f\"Number of noise poitns: {n_noise}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dbscan_dist = dict(Counter(pitch_cluster_list))\n",
    "dbscan_x = list(dbscan_dist.keys())\n",
    "dbscan_y = list(dbscan_dist.values())\n",
    "plt.bar(dbscan_x, dbscan_y, alpha=0.5)\n",
    "plt.bar([3,4,5,6,7,8,9], [105,287,235,114,79,42,32], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dbscan_dist = dict(Counter(pitch_cluster_list))\n",
    "dbscan_x = list(dbscan_dist.keys())\n",
    "dbscan_y = list(dbscan_dist.values())\n",
    "plt.bar(dbscan_x, dbscan_y, alpha=0.5)\n",
    "plt.bar([3,4,5,6,7,8,9], [105,287,235,114,79,42,32], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means with Elbow method and Silhouette averages to find optimal k"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# range of number of clusters\n",
    "num_clusters = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]  #range(2, 10)\n",
    "\n",
    "# initiate the models\n",
    "kmeans = []\n",
    "for i in num_clusters:\n",
    "    print(f\"initializing a model for {i} clusters\")\n",
    "    kmeans.append(KMeans(n_clusters=i, n_jobs=-1))\n",
    "\n",
    "# compute the scores for each fit\n",
    "score = []\n",
    "for i, k in enumerate(num_clusters):\n",
    "    print(f\"fitting the data to {k} clusters\")\n",
    "    score.append(kmeans[i].fit(cluster_train_data_scaled).score(cluster_train_data_scaled))\n",
    "\n",
    "# cluster labels\n",
    "cluster_labels = []\n",
    "for i, k in enumerate(num_clusters):\n",
    "    print(f\"labeling the data for {k} clusters\")\n",
    "    cluster_labels.append(kmeans[i].fit_predict(cluster_train_data_scaled))\n",
    "\n",
    "# silhouette avgs\n",
    "silhouette_avgs = []\n",
    "for i, k in enumerate(num_clusters):\n",
    "    print(f\"computing silhouette avgs for {k} clusters\")\n",
    "    silhouette_avgs.append(silhouette_score(cluster_train_data_scaled, cluster_labels[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(num_clusters, score)\n",
    "plt.title(\"Elbow Curve\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"K-Means Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.plot(num_clusters, silhouette_avgs)\n",
    "plt.title(\"Silhouette Averages\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silouette Average\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-means with Gap statistic to find optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of clusters is: 3\n"
     ]
    }
   ],
   "source": [
    "def optimalK(data, nrefs=3, maxClusters=15):\n",
    "    \"\"\"\n",
    "    Calculates KMeans optimal K using Gap Statistic from Tibshirani, Walther, Hastie\n",
    "    Params:\n",
    "        data: ndarry of shape (n_samples, n_features)\n",
    "        nrefs: number of sample reference datasets to create\n",
    "        maxClusters: Maximum number of clusters to test for\n",
    "    Returns: (gaps, optimalK)\n",
    "    \"\"\"\n",
    "    gaps = np.zeros((len(range(1, maxClusters)),))\n",
    "    resultsdf = pd.DataFrame({'clusterCount':[], 'gap':[]})\n",
    "    for gap_index, k in enumerate(range(1, maxClusters)):\n",
    "\n",
    "        # Holder for reference dispersion results\n",
    "        refDisps = np.zeros(nrefs)\n",
    "\n",
    "        # For n references, generate random sample and perform kmeans getting resulting dispersion of each loop\n",
    "        for i in range(nrefs):\n",
    "            \n",
    "            # Create new random reference set\n",
    "            randomReference = np.random.random_sample(size=data.shape)\n",
    "            \n",
    "            # Fit to it\n",
    "            km = KMeans(k, n_jobs=-1)\n",
    "            km.fit(randomReference)\n",
    "            \n",
    "            refDisp = km.inertia_\n",
    "            refDisps[i] = refDisp\n",
    "\n",
    "        # Fit cluster to original data and create dispersion\n",
    "        km = KMeans(k)\n",
    "        km.fit(data)\n",
    "        \n",
    "        origDisp = km.inertia_\n",
    "\n",
    "        # Calculate gap statistic\n",
    "        gap = np.log(np.mean(refDisps)) - np.log(origDisp)\n",
    "\n",
    "        # Assign this loop's gap statistic to gaps\n",
    "        gaps[gap_index] = gap\n",
    "        \n",
    "        resultsdf = resultsdf.append({'clusterCount':k, 'gap':gap}, ignore_index=True)\n",
    "\n",
    "    return (gaps.argmax() + 1, resultsdf)  # Plus 1 because index of 0 means 1 cluster is optimal, index 2 = 3 clusters are optimal\n",
    "\n",
    "k, _ = optimalK(cluster_train_data_scaled)\n",
    "print(f\"The optimal number of clusters is: {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14054.041725128656\n"
     ]
    }
   ],
   "source": [
    "# perform k-means clustering (with number of clusters determined from elbow method)\n",
    "kmeans = KMeans(n_clusters=9, n_jobs=-1).fit(cluster_train_data_scaled)\n",
    "\n",
    "print(kmeans.score(cluster_train_data_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### categorize pitches using k-means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_index</th>\n",
       "      <th>player_name</th>\n",
       "      <th>pfx_x_scaled</th>\n",
       "      <th>pfx_z_scaled</th>\n",
       "      <th>release_speed_scaled</th>\n",
       "      <th>cluster_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>2017_656756</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>0.470616</td>\n",
       "      <td>0.537023</td>\n",
       "      <td>0.740683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>2017_656756</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>0.614863</td>\n",
       "      <td>0.686330</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>2017_656756</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>0.488993</td>\n",
       "      <td>0.423302</td>\n",
       "      <td>0.656832</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>2017_656756</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>0.618048</td>\n",
       "      <td>0.666861</td>\n",
       "      <td>0.818323</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4950</th>\n",
       "      <td>2017_656756</td>\n",
       "      <td>Jordan Montgomery</td>\n",
       "      <td>0.504702</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>0.667702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        obs_index        player_name  pfx_x_scaled  pfx_z_scaled  \\\n",
       "4946  2017_656756  Jordan Montgomery      0.470616      0.537023   \n",
       "4947  2017_656756  Jordan Montgomery      0.614863      0.686330   \n",
       "4948  2017_656756  Jordan Montgomery      0.488993      0.423302   \n",
       "4949  2017_656756  Jordan Montgomery      0.618048      0.666861   \n",
       "4950  2017_656756  Jordan Montgomery      0.504702      0.465083   \n",
       "\n",
       "      release_speed_scaled  cluster_number  \n",
       "4946              0.740683               0  \n",
       "4947              0.821429               4  \n",
       "4948              0.656832               5  \n",
       "4949              0.818323               4  \n",
       "4950              0.667702               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def categorize_pitches(df):\n",
    "\n",
    "    df = df[['obs_index', 'player_name', 'pfx_x', 'pfx_z', 'release_speed']]\n",
    "\n",
    "    df['pfx_x_scaled'] = pfx_x_scaler.transform(df['pfx_x'].as_matrix().reshape(-1,1))\n",
    "    df['pfx_z_scaled'] = pfx_z_scaler.transform(df['pfx_z'].as_matrix().reshape(-1,1))\n",
    "    df['release_speed_scaled'] = release_speed_scaler.transform(df['release_speed'].as_matrix().reshape(-1,1))\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df = df[['obs_index', 'player_name', 'pfx_x_scaled', 'pfx_z_scaled', 'release_speed_scaled']]\n",
    "\n",
    "    df['cluster_number'] = kmeans.predict(df[['pfx_x_scaled', 'pfx_z_scaled', 'release_speed_scaled']]) \n",
    "    \n",
    "    return df\n",
    "\n",
    "train_data_categorized = categorize_pitches(train_data)\n",
    "\n",
    "test_data_categorized = categorize_pitches(test_data)\n",
    "\n",
    "test_data_categorized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### turn counts of cluster types into features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884, 9)\n",
      "                 0      1      2       3       4      5       6      7      8\n",
      "2012_502706  385.0    NaN  171.0     NaN  1871.0  289.0     NaN    NaN   27.0\n",
      "2012_133225  940.0  299.0   15.0   168.0     NaN   45.0   818.0  460.0    NaN\n",
      "2012_456167  161.0  130.0    NaN    23.0     NaN    NaN   668.0  190.0  246.0\n",
      "2012_477132  187.0    NaN   41.0  1929.0   111.0  395.0   375.0  414.0    NaN\n",
      "2012_285064   45.0  666.0    NaN   287.0     NaN  160.0  1091.0  425.0  380.0\n",
      "(190, 9)\n",
      "                 0       1      2      3       4      5      6      7      8\n",
      "2017_656756  537.0     NaN  311.0  440.0   823.0  376.0    NaN    NaN   28.0\n",
      "2017_592170  237.0   294.0   19.0  315.0     NaN    NaN  429.0  150.0  310.0\n",
      "2017_572020  205.0     NaN   33.0  214.0  1319.0  477.0    NaN    NaN    NaN\n",
      "2017_606131  541.0  1553.0    NaN    NaN     NaN  218.0  101.0   93.0   40.0\n",
      "2017_621389   73.0     NaN  606.0   17.0  1483.0  306.0    NaN    NaN   24.0\n"
     ]
    }
   ],
   "source": [
    "def convert_counts_to_features(df, thresh):\n",
    "    \n",
    "    obs_list = list(df['obs_index'].unique())\n",
    "\n",
    "    pitch_counts_df = pd.DataFrame(columns=[0,1,2])\n",
    "\n",
    "    for i, obs in enumerate(obs_list):\n",
    "\n",
    "        temp_df = df[df['obs_index']==obs]\n",
    "\n",
    "        pitch_df = pd.DataFrame(dict(Counter(temp_df['cluster_number'])), index=[obs])\n",
    "\n",
    "        pitch_counts_df = pitch_counts_df.append(pitch_df)\n",
    "        \n",
    "    # if number of pitches is below thresh, replace count with NaN\n",
    "    def num_pitches_thresh(x):\n",
    "        if x <= thresh:\n",
    "            return np.nan\n",
    "        else:\n",
    "            return x\n",
    "    for col in pitch_counts_df.columns.tolist():\n",
    "        pitch_counts_df[col] = pitch_counts_df[col].apply(num_pitches_thresh)\n",
    "    return pitch_counts_df\n",
    "\n",
    "train_pitch_counts_df = convert_counts_to_features(train_data_categorized, thresh=10)\n",
    "\n",
    "test_pitch_counts_df = convert_counts_to_features(test_data_categorized, thresh=10)\n",
    "\n",
    "print(train_pitch_counts_df.shape)\n",
    "print(train_pitch_counts_df.head())\n",
    "\n",
    "print(test_pitch_counts_df.shape)\n",
    "print(test_pitch_counts_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count the number of used clusters for each observation\n",
    "\n",
    "For comparison to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>num_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012_502706</th>\n",
       "      <td>385.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1871.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_133225</th>\n",
       "      <td>940.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_456167</th>\n",
       "      <td>161.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>668.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_477132</th>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1929.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_285064</th>\n",
       "      <td>45.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>160.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0      1      2       3       4      5       6      7      8  \\\n",
       "2012_502706  385.0    NaN  171.0     NaN  1871.0  289.0     NaN    NaN   27.0   \n",
       "2012_133225  940.0  299.0   15.0   168.0     NaN   45.0   818.0  460.0    NaN   \n",
       "2012_456167  161.0  130.0    NaN    23.0     NaN    NaN   668.0  190.0  246.0   \n",
       "2012_477132  187.0    NaN   41.0  1929.0   111.0  395.0   375.0  414.0    NaN   \n",
       "2012_285064   45.0  666.0    NaN   287.0     NaN  160.0  1091.0  425.0  380.0   \n",
       "\n",
       "             num_clusters  \n",
       "2012_502706             5  \n",
       "2012_133225             7  \n",
       "2012_456167             6  \n",
       "2012_477132             7  \n",
       "2012_285064             7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pitch_counts_df['num_clusters'] = 0\n",
    "\n",
    "for i in range(len(train_pitch_counts_df)):\n",
    "    \n",
    "    train_pitch_counts_df['num_clusters'].iloc[i] = pd.notnull(train_pitch_counts_df.iloc[i,0]) + pd.notnull(train_pitch_counts_df.iloc[i,1]) +\\\n",
    "                                                    pd.notnull(train_pitch_counts_df.iloc[i,2]) + pd.notnull(train_pitch_counts_df.iloc[i,3]) +\\\n",
    "                                                    pd.notnull(train_pitch_counts_df.iloc[i,4]) + pd.notnull(train_pitch_counts_df.iloc[i,5]) +\\\n",
    "                                                    pd.notnull(train_pitch_counts_df.iloc[i,6]) + pd.notnull(train_pitch_counts_df.iloc[i,7]) +\\\n",
    "                                                    pd.notnull(train_pitch_counts_df.iloc[i,8])\n",
    "\n",
    "\n",
    "train_pitch_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_count = dict(Counter(train_pitch_counts_df['num_clusters']))\n",
    "plt.bar(list(cluster_count.keys()), list(cluster_count.values()), alpha=0.5)\n",
    "plt.bar([3, 4, 5, 6, 7, 8 , 9], [105, 287, 235, 114, 79, 42, 32], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use MAPE as our evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, train a baseline model with just release_speed and strike_pct as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean K rate for training data: 7.31\n",
      "Mean K rate for testing data: 7.94\n",
      "Linear Regression MAPE: 17.2\n"
     ]
    }
   ],
   "source": [
    "base_train_data = train_data[['obs_index', 'K/9', 'release_speed', 'strike_pct']]\n",
    "base_train_data = pd.DataFrame(base_train_data.groupby(['obs_index', 'K/9', 'strike_pct'])['release_speed'].mean())\n",
    "base_train_data.reset_index(inplace=True, drop=False)\n",
    "base_train_data.drop('obs_index', axis=1, inplace=True)\n",
    "\n",
    "base_test_data = test_data[['obs_index', 'K/9', 'release_speed', 'strike_pct']]\n",
    "base_test_data = pd.DataFrame(base_test_data.groupby(['obs_index', 'K/9', 'strike_pct'])['release_speed'].mean())\n",
    "base_test_data.reset_index(inplace=True, drop=False)\n",
    "base_test_data.drop('obs_index', axis=1, inplace=True)\n",
    "base_test_data.head()\n",
    "\n",
    "X_train = base_train_data.drop('K/9', axis=1)\n",
    "y_train = base_train_data['K/9']\n",
    "\n",
    "X_test = base_test_data.drop('K/9', axis=1)\n",
    "y_test = base_test_data['K/9']\n",
    "\n",
    "print(f'Mean K rate for training data: {round(base_train_data[\"K/9\"].mean(), 2)}')\n",
    "print(f'Mean K rate for testing data: {round(base_test_data[\"K/9\"].mean(), 2)}')\n",
    "      \n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "      \n",
    "print(f'Linear Regression MAPE: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, prepare the clustered data by merging the K rate data with pitch counts data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training data: (885, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K/9</th>\n",
       "      <th>strike_pct</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012_112526</th>\n",
       "      <td>5.38</td>\n",
       "      <td>0.700140</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_117955</th>\n",
       "      <td>3.47</td>\n",
       "      <td>0.602652</td>\n",
       "      <td>324.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>993.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_119154</th>\n",
       "      <td>5.98</td>\n",
       "      <td>0.627504</td>\n",
       "      <td>486.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>158.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_120485</th>\n",
       "      <td>8.24</td>\n",
       "      <td>0.650752</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>429.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012_133225</th>\n",
       "      <td>7.96</td>\n",
       "      <td>0.643013</td>\n",
       "      <td>940.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>818.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              K/9  strike_pct      0       1     2      3      4      5  \\\n",
       "2012_112526  5.38    0.700140  127.0  1265.0   0.0    0.0    0.0    0.0   \n",
       "2012_117955  3.47    0.602652  324.0   892.0   0.0   20.0    0.0   35.0   \n",
       "2012_119154  5.98    0.627504  486.0   750.0  24.0  414.0    0.0    0.0   \n",
       "2012_120485  8.24    0.650752   71.0     0.0  96.0  429.0  173.0  137.0   \n",
       "2012_133225  7.96    0.643013  940.0   299.0  15.0  168.0    0.0   45.0   \n",
       "\n",
       "                 6      7      8  \n",
       "2012_112526  485.0  161.0    0.0  \n",
       "2012_117955   24.0  993.0   45.0  \n",
       "2012_119154  565.0  183.0  158.0  \n",
       "2012_120485    0.0  214.0    0.0  \n",
       "2012_133225  818.0  460.0    0.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data.set_index('obs_index', inplace=True, drop=True)\n",
    "strike_train_data = train_data[['K/9', 'strike_pct']]\n",
    "\n",
    "train_data_Kpct = pd.merge(strike_train_data, train_pitch_counts_df, left_index=True, right_index=True)\n",
    "train_data_Kpct.drop('num_clusters', axis=1, inplace=True)\n",
    "train_data_Kpct.fillna(value=0.0, inplace=True)\n",
    "\n",
    "train_data_Kpct.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Shape of the training data: {train_data_Kpct.shape}\")\n",
    "train_data_Kpct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the test data: (191, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K/9</th>\n",
       "      <th>strike_pct</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017_112526</th>\n",
       "      <td>5.60</td>\n",
       "      <td>0.675853</td>\n",
       "      <td>140.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_276520</th>\n",
       "      <td>5.70</td>\n",
       "      <td>0.656601</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>495.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_282332</th>\n",
       "      <td>7.26</td>\n",
       "      <td>0.635897</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>364.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_285079</th>\n",
       "      <td>6.44</td>\n",
       "      <td>0.660055</td>\n",
       "      <td>509.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>884.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017_407793</th>\n",
       "      <td>7.86</td>\n",
       "      <td>0.640332</td>\n",
       "      <td>709.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              K/9  strike_pct      0      1      2      3      4      5  \\\n",
       "2017_112526  5.60    0.675853  140.0  660.0   15.0   75.0    0.0    0.0   \n",
       "2017_276520  5.70    0.656601   16.0    0.0  462.0   29.0    0.0   46.0   \n",
       "2017_282332  7.26    0.635897  229.0    0.0  364.0  545.0  472.0  206.0   \n",
       "2017_285079  6.44    0.660055  509.0    0.0  244.0   21.0    0.0  884.0   \n",
       "2017_407793  7.86    0.640332  709.0  560.0  189.0   76.0    0.0   15.0   \n",
       "\n",
       "                 6       7      8  \n",
       "2017_112526  353.0  1026.0    0.0  \n",
       "2017_276520   16.0   495.0   77.0  \n",
       "2017_282332    0.0   515.0    0.0  \n",
       "2017_285079    0.0   872.0  337.0  \n",
       "2017_407793  780.0   154.0  272.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_data.set_index('obs_index', inplace=True, drop=True)\n",
    "strike_test_data = test_data[['K/9', 'strike_pct']]\n",
    "\n",
    "test_data_Kpct = pd.merge(strike_test_data, test_pitch_counts_df, left_index=True, right_index=True)\n",
    "#test_data_Kpct.drop('num_clusters', axis=1, inplace=True)\n",
    "test_data_Kpct.fillna(value=0.0, inplace=True)\n",
    "\n",
    "test_data_Kpct.drop_duplicates(inplace=True)\n",
    "\n",
    "print(f\"Shape of the test data: {test_data_Kpct.shape}\")\n",
    "test_data_Kpct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split data into training and test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(885, 10)\n",
      "(885,)\n",
      "(191, 10)\n",
      "(191,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train_data_Kpct.drop('K/9', axis=1)\n",
    "y_train = train_data_Kpct['K/9']\n",
    "\n",
    "X_test = test_data_Kpct.drop('K/9', axis=1)\n",
    "y_test = test_data_Kpct['K/9']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 17.0\n"
     ]
    }
   ],
   "source": [
    "lin_reg = LinearRegression()\n",
    "\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lin_reg.predict(X_test)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Off-the-shelf) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 17.5\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor()\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_reg.predict(X_test)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Off-the-shelf) AdaBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 17.0\n"
     ]
    }
   ],
   "source": [
    "ab_reg = AdaBoostRegressor()\n",
    "\n",
    "ab_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ab_reg.predict(X_test)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized Random Forest\n",
    "\n",
    "Using Scikit-Learn's GridSearchCV to find the optimal set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed:   55.0s\n",
      "[Parallel(n_jobs=-1)]: Done 632 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 110, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 8, 'n_estimators': 1000}\n",
      "Mean Absolute Error: 16.3\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimized AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 105 candidates, totalling 315 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 273 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 315 out of 315 | elapsed:   26.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 100}\n",
      "Mean Absolute Percentage Error: 16.9\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50, 100, 200, 300, 1000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0, 5.0, 10.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "# Create a based model\n",
    "ab = AdaBoostRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = ab, param_grid = param_grid, cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error: {round(mean_absolute_percentage_error(y_test, y_pred), 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
